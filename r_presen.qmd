---
title: "How to analysis in R"
author: "Nozomi Niimi"
format:
  revealjs:
    smaller: true
---

## What is R?

* 統計に特化したプログラミング言語
* Ross Ihaka, Robert Gentlemanらによって1993年に開発
* ベースとなる言語がSだった為、Sの前に立つという意味で「R」を選んだらしい
* Rのみだと"すごい電卓"だけど、packageを入れることによって何でもできる

## Rの利点

* 完全に無料！
* 統計に特化している
    * 最新の統計解析手法が整っている
    * 統計解析が非常に楽になるような仕組みが整っている
* 30年間の歴史があり、packageの遺産が多い
    * 2021年時点で20000近く！

## Rの欠点

* 最初はとっつきにくい
* Packageの質にムラがある
    * CRANは動きは保証するけど、その中身は保証しない
* 後方互換を考えていない
    * Packageの動作がバージョンによって異なることがある

## Rの統計のコツ

* Rstudioを使う
* 便利なパッケージを使う
    * 車輪の再発明はしない
* 基本はインターネットで情報を探す
    * 本だと情報が古くて動かないこともしばしば
* 極力、自動化して楽をする
    * 人間はコピー & ペーストだとミスをする
* 関数の名前の前には、必ず"package名::"をつける！
    * namespaceの衝突の回避

## Package使用の注意点

* 更新してされずに使えなくなるものもある
    * `funModeling`パッケージ好きだったのに...
* パッケージの質は玉石混交
    * 基本統計とかの再現可能なものは大体大丈夫
    * 統計パッケージの場合は以下を確認すると良い
        * citationが査読付き論文か(RjournalやJSS)
        * rOpenSciのものかどうか
        * 企業が関わっているか(Positなど)
        * maintainerが大学所属かどうか

## 全員にオススメパッケージ

* 何も考えず`tidyverse`
* それ以外だと`easystats`は使いやすい
* `ggpubr`とか`survminer`とかもオススメ(更新されないのが心配……)

## 本日のお話

* 基本的な統計解析の流れ
* 各々でおすすめのパッケージ
* 最後に

## package読み込み
```{r}
library(tidyverse)
library(easystats)
library(janitor)
library(skimr)
library(gtsummary)
library(tableone)
library(finalfit)
library(rms)
library(ggpubr)
library(survminer)
library(ggsurvfit)
```

## 基本的な解析の方法

```{mermaid}
flowchart LR
    A(Raw data) --> B(Prepare)
    B --> C(Make Table 1)
    C --> D{data analysis: \n  Logistic regression \n  survival analysis etc}
    D --> E[Make other tables]
    D --> F[Visualization]
```


## Raw data
* Dataの読み込み
* excelかreadxlが最も多い
* 基本は`tidyverse`の中のパッケージにおまかせ
    * SPSS, STATAファイルも`haven`で行ける
* guess_maxは基本大きい数字のほうが良い
    * NAが多いデータだとデータ型を間違えることがある

## Raw data 2
```{r}
#| echo: false
dat <- readr::read_csv("testdata.csv", guess_max = 418)
head(dat)
```


## Prepare 1. EDA

* ざっとはskimrがおすすめ
* Crosstableはjanitorやgtsummaryがおすすめ
* 他のものとの関係性はpair plotもおすすめ
    * 列数が多いと重い & 見にくいので注意

## Prepare 1. EDA実践

```{r}
#| echo: true
print(skimr::skim(dat))

gtsummary::tbl_cross(dat, row = edema, col = status, percent = "row")

dat |> 
  dplyr::select(age, bili, chol, albumin, copper, alk.phos, ast, platelet, protime) |> 
  GGally::ggpairs()
```


## Prepare 2. data cleaning
* 動きの基本は3つ
    * 列を選択する`select`
    * 新しい列を作る`mutate`
    * 行を選択する`filter`
* `base`の`subset()`や`data.tableの[]`を使えば上記は同時に出来る
    * 見やすさとの兼ね合い
* `select`->`mutate`->`filter`の順番がおすすめ
## Prepare 2. 実践
```{r}
# ...1を除き、status 0,1のみに、最後に
dat1 <- dat |>
  dplyr::select(-`...1`) |> 
  dplyr::mutate(across(c(chol, copper, alk.phos, ast, trig, platelet, protime), \(x){tidyr::replace_na(x, median(x, na.rm = TRUE))}))|>
  dplyr::filter(status %in% c(0,1)) |> 
  dplyr::filter(!is.na(trt))
```

## Make Table 1
* `tableone`や`gtsummary`、`finalfit` etc
    * 個人的には圧倒的に`tableone`がオススメ
* labelを付けると楽(おまけだが)

## Make Table 1: 実践
```{r}
all_cols <- c("age", "sex", "ascites", "hepato", "spiders", "edema", "bili", "chol", "albumin", "copper", "alk.phos", "ast", "trig", "platelet", "protime", "stage")

cat_cols <- c("sex", "ascites", "hepato", "spiders", "edema", "stage")

cont_cols <- base::intersect(all_cols, cat_cols)

tableone::CreateTableOne(vars = all_cols, 
data = dat1, 
factorVars = cat_cols,
strata = "trt" ) |> 
  print(nonnormal = cont_cols) |> 
  tibble::as_tibble(rownames = "Variables") |> 
  dplyr::select(-test)


```

## data analysis
* 殆んどの解析は元々入っている`stats`、`survival`のみで可能
    * パッケージ追加は不要
* 追加するとしたら`rms`とか(splineなど)
* 競合リスク解析は`cmprsk`よりは`finalfit`か`tidycmprsk`がおすすめ
::: {.callout-tip}
## Tip with Title
結果を取り扱いしやすくするパッケージを使う事のをオススメ
:::

## data analysis: 結果まとめパッケージ
* `finalfit`, `gtsummary`, `modelsummary`など
* Excelに出したり、Figureに作ることまで考えるなら`easystats`の`parameters`や`broom`がオススメ

## 例

```{r}
#| echo: true
fit <- survival::coxph(Surv(time, status) ~ trt + age + sex, data = dat1)

gtsummary::tbl_regression(fit, exponentiate = TRUE)

tidyr::drop_na(dat, time, status, trt, age, sex) |> 
  finalfit::crrmulti(.data = _, dependent = "Surv(time, status)", explanatory = c("trt", "age", "sex")) |> 
  finalfit::fit2df()

rms::cph(Surv(time, status) ~ trt + rcs(age, 3) + sex, data = dat1) |> 
  parameters::model_parameters(fit, exponentiate = TRUE)
```


## Make other tables
## Visualization
* 地味に面倒な作業
* 画像の大きさとdpiの調整が非常に面倒
* 基本として、**ラスター画像**と**ベクター画像**があることを知っておく
    * ラスター画像はいわゆる点描画、拡大するとぼやける
        * jpeg, tiff, pngなど
    * ベクター画像は絵の式が入っている為拡大してもぼやけない
        * pdf, wmf, eps, svgなど
* svg fileなどに出しておくと後々楽かもしれない
## flowchart
```{r}
ExclusionTable::exclusion_table(data = dat, 
                                exclusion_criteria = c("status == 2", 
                                 "is.na(trt)"), 
                                labels_exclusion = c(
                                    "Non liver death", 
                                    "missing for treat"
                                ))


```

## 結論
* `tidyverse`+`tableone`+`gtsummary`+`ggpubr`+`broom`+`cowplot`が無難
    * flowchartは`ExclusionTable`+`consort`
    * forestplotは`forestplot`か`forestploter`
    * 生存解析をするなら`finalfit`+`survminer`/`ggsurvfit`
* 特殊な統計解析するなら`easystats`が一つあると便利
* 癖があるけど`modelsummary`は自由度が高い
