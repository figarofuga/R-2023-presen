---
title: "How to analysis in R"
author: "Nozomi Niimi"
execute:
  echo: true
format:
  revealjs:
    smaller: true
---

## What is R?

* 統計に特化したプログラミング言語
* Ross Ihaka, Robert Gentlemanらによって1993年に開発
* ベースとなる言語がSだった為、Sの前に立つという意味で「R」を選んだらしい
* Rのみだと"すごい電卓"だけど、packageを入れることによって何でもできる!!
* CRANという団体がpackageの質を保証している
    * 最近ではR-Universe等の他の団体も出来てきている

## Rの利点

* 完全に無料！
* 統計に特化している
    * 最新の統計解析手法が整っている
    * 統計解析が非常に楽になるような仕組みが整っている
* 30年間の歴史があり、packageの遺産が多い
    * 2021年時点でCRAN登録数が20000近く！
* packageの利用こそが最大の利点！

## Rの欠点

* 最初はとっつきにくい
* Packageの質にムラがある
    * CRANは動く事は保証するけど、その中身は保証しない
* 後方互換を考えていない
    * Packageの動作がバージョンによって異なることがある
        * Ex. `MatchIt`はversion 3と4で違う結果を出す
    * PackageがRの進化に追いつかずに動作が動かない事がある
        * Ex. `funModeling`便利だったがArchiveされてしまった
* 適切なPackageを選んで使う事が重要！

## Package使用の注意点とコツ

* 更新してされずに使えなくなるものもある
    * `funModeling`パッケージ好きだったのに...
* パッケージの質は玉石混交
    * 基礎統計とかの再現可能なものは大体大丈夫
    * 統計パッケージの場合は以下を確認すると良い
        * citationが査読付き論文か(RjournalやJSS)
        * rOpenSciのものかどうか
        * 企業が関わっているか(Posit社など)
        * maintainerが大学所属かどうか
* 上手く解析が出来るまでパッケージやRのVersionは変更しない
    * `renv`を使うか`utils::sessionInfo()`のデータを何処かに残しておこう
* 関数の名前の前には、必ず"package名::"をつける！
    * namespaceの衝突の回避

## 全員にオススメパッケージ

* 何も考えず`tidyverse`
* それ以外だと`easystats`は使いやすい
* `ggpubr`とか`survminer`とかもオススメ(更新されないのが心配……)

## 本日のお話

* 基本的な統計解析の流れ
* 各々でおすすめのパッケージ
* 最後に

## package読み込み
```{r}
library(tidyverse)
library(easystats)
library(janitor)
library(skimr)
library(gtsummary)
library(tableone)
library(finalfit)
library(rms)
library(ggpubr)
library(survminer)
library(ggsurvfit)
library(magick)
library(rsvg)
library(DiagrammeRsvg)
```

## 基本的な解析の方法

```{mermaid}
flowchart LR
    A(Raw data) --> B(Prepare)
    B --> C(Make Table 1)
    C --> D{data analysis: \n  Logistic regression \n  survival analysis etc}
    D --> E[Make other tables]
    D --> F[Visualization]
```


## Raw data
* Dataの読み込み
* excelかreadxlが最も多い
* 基本は`tidyverse`の中のパッケージにおまかせ
    * SPSS, STATAファイルも`haven`で行ける
* guess_maxは基本大きい数字のほうが良い
    * NAが多いデータだとデータ型を間違えることがある

## Raw data 2
```{r}
#| echo: false
dat <- readr::read_csv("testdata.csv", guess_max = 418)
head(dat)
```


## Prepare 1. EDA

* ざっとはskimrがおすすめ
* Crosstableはjanitorやgtsummaryがおすすめ
* 他のものとの関係性はpair plotもおすすめ
    * 列数が多いと重い & 見にくいので注意

## Prepare 1. EDA実践

```{r}
#| echo: true
print(skimr::skim(dat))

gtsummary::tbl_cross(dat, row = edema, col = status, percent = "row")

dat |> 
  dplyr::select(age, bili, chol, albumin, copper, alk.phos, ast, platelet, protime) |> 
  GGally::ggpairs()
```


## Prepare 2. data cleaning
* 動きの基本は3つ
    * 列を選択する`select`
    * 新しい列を作る`mutate`
    * 行を選択する`filter`
* `base`の`subset()`や`data.tableの[]`を使えば上記は同時に出来る
    * 見やすさとの兼ね合い
* `select`->`mutate`->`filter`の順番がおすすめ

## Prepare 2. 実践
```{r}
# ...1を除き、status 0,1のみに、最後に
dat1 <- dat |>
  dplyr::select(-`...1`) |> 
  dplyr::mutate(across(c(chol, copper, alk.phos, ast, trig, platelet, protime), \(x){tidyr::replace_na(x, median(x, na.rm = TRUE))}))|>
  dplyr::filter(status %in% c(0,1)) |> 
  dplyr::filter(!is.na(trt))
```

## Make Table 1
* `tableone`や`gtsummary`、`finalfit` etc
    * 個人的には圧倒的に`tableone`がオススメ
* labelを付けると楽(おまけだが)

## Make Table 1: 実践
```{r}
all_cols <- c("age", "sex", "ascites", "hepato", "spiders", "edema", "bili", "chol", "albumin", "copper", "alk.phos", "ast", "trig", "platelet", "protime", "stage")

cat_cols <- c("sex", "ascites", "hepato", "spiders", "edema", "stage")

cont_cols <- base::intersect(all_cols, cat_cols)

tableone::CreateTableOne(vars = all_cols, 
data = dat1, 
factorVars = cat_cols,
strata = "trt" ) |> 
  print(nonnormal = cont_cols) |> 
  tibble::as_tibble(rownames = "Variables") |> 
  dplyr::select(-test)


```

## data analysis
* 殆んどの解析は元々入っている`stats`、`survival`のみで可能
    * パッケージ追加は不要
* 追加するとしたら`rms`とか(splineなど)
* 競合リスク解析は`cmprsk`よりは`finalfit`か`tidycmprsk`がおすすめ

::: {.callout-tip}
## Tip with Title
**結果を取り扱いしやすくするパッケージを使う事のをオススメ**
:::

## data analysis: 結果まとめパッケージ
* `finalfit`, `gtsummary`, `modelsummary`など
    * サポートしているモデルが違うのでそれで選べば良い
* Excelに出したり、Figureに作ることまで考えるなら`easystats`の`parameters`や`broom`がオススメ

## 例

```{r}
#| echo: true
fit <- survival::coxph(Surv(time, status) ~ trt + age + sex, data = dat1)

gtsummary::tbl_regression(fit, exponentiate = TRUE)

parameters::model_parameters(fit, exponentiate = TRUE)

tidyr::drop_na(dat, time, status, trt, age, sex) |> 
  finalfit::crrmulti(.data = _, dependent = "Surv(time, status)", explanatory = c("trt", "age", "sex")) |> 
  finalfit::fit2df()

rms::cph(Surv(time, status) ~ trt + rcs(age, 3) + sex, data = dat1) |> 
  modelsummary::modelsummary(exponentiate = TRUE, output = "markdown")
```


## Make other tables

## Visualization
* 地味に面倒な作業
* 画像の大きさとdpiの調整が非常に面倒
* 基本として、**ラスター画像**と**ベクター画像**があることを知っておく
    * ラスター画像はいわゆる点描画、拡大するとぼやける
        * jpeg, tiff, pngなど
    * ベクター画像は絵の式が入っている為拡大してもぼやけない
        * pdf, wmf, eps, svgなど
* svg fileなどに出しておくと後々楽かもしれない
## flowchart

* `consort` packageか`Gmisc`がおすすめ
    * `consort`で`grviz`形式で作るのが良い
* ぶっちゃけ、Rで作るのが大変過ぎて普通にdraw.ioとかPPTXとかで作ったほうが楽
* ただし、データが変わったり除外基準が追加になったりするのでやり方は知っておいても良い

## flowchart実践
```{r}
extab <- ExclusionTable::exclusion_table(data = dat, 
                                exclusion_criteria = c("status == 2", 
                                 "is.na(trt)"), 
                                labels_exclusion = c(
                                    "non_liver_death", 
                                    "missing_for_treat"
                                ))

ex_list <- base::split(extab$table_ex, f = 1:nrow(extab$table_ex)) |> stats::setNames(nm = extab$table_ex$exclusion)

flowchart <- consort::add_box(txt = paste0("All cohort: n = ", ex_list$non_liver_death$n_prior)) |> 
  consort::add_side_box(txt = paste0("Excluded: n = ", ex_list$TOTAL$n_excluded,"\n\u2022 Non liver death: n = ", ex_list$non_liver_death$n_excluded, "\n\u2022 Missing for treatment: n = ", ex_list$missing_for_treat$n_excluded)) |> 
  consort::add_box(txt = paste0("Analytic cohort: n = ", ex_list$TOTAL$n_post)) |> 
  consort::add_split(txt = c(paste0("Treatment: n = ", nrow(base::subset(dat1, subset = trt == 1))), paste0("Placebo: n = ", nrow(base::subset(dat1, subset = trt == 0)))))
plot(flowchart, grViz = TRUE)

# plot(flowchart, grViz = TRUE) |> 
#     DiagrammeRsvg::export_svg() |> 
#     charToRaw() |> 
#     rsvg::rsvg_pdf("flowchart.pdf")

# plot(flowchart, grViz = TRUE) |> 
#     DiagrammeRsvg::export_svg() |> 
#     charToRaw() |> 
#     rsvg::rsvg_svg("flowchart.svg")

# magick::image_read_svg("flowchart.svg") |> 
#   magick::image_convert(format = "tiff") |> 
#   magick::image_write("flowchart.tiff", compression = 'lzw', density = 900)

```

## 結論
* `tidyverse`+`tableone`+`gtsummary`+`ggpubr`+`broom`+`cowplot`が無難
    * flowchartは`ExclusionTable`+`consort`
    * forestplotは`forestplot`か`forestploter`
    * 生存解析をするなら`finalfit`+`survminer`/`ggsurvfit`
* 特殊な統計解析するなら`easystats`が一つあると便利

